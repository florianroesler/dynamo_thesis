\chapter{Introduction}
\label{intro}
At the current state of technology, computers with multiple compute processing units (abbr. CPU) cores are common and even small devices, such as smartphones, employ multi-core architectures\cite{arm_big_little}. Programs that aim at harnessing the full potential of a multi-core computer have to be constructed accordingly.

Considering complex scientific use cases, certain computations may require more computational power than a single machine can provide. Therefore it is mandatory to connect multiple machines to collectively solve a problem. For example, researchers recently created a method to break a widely used cryptographic hash function, requiring resources equivalent to more than 6500 CPU-years to compute\cite{shattered}. A single machine at the current level of technology would therefore require too long in order to deliver the desired results. At the same time certain physical factors are limiting further quick advancements concerning CPU performance\cite{end_of_moores_law}\cite{end_of_silicon} so that many problems will still require multiple machines in the future for time efficient computations.

As of today, there are various available approaches for programmers to distribute workloads across multiple cores of a single machine or among multiple machines grouped as a cluster. Enhancing single threaded code to a multithreaded program that runs on multiple machines in parallel adds several layers of complexity to a project, which may introduce errors and increased maintenance efforts.

Frameworks, such as Open Multi-Processing (abbr. OpenMP), CUDA or Open Computing Language (abbr. OpenCL), allow for the parallel utilization of resources within a machine but in return require programmers to learn extensive Application Programming Interfaces (abbr. API) or to write code in low-level languages, e.g.~C.
At the same time cluster distribution approaches, such as Hadoop MapReduce, require extended configuration management of the participating nodes. Other techniques like the Message Passing Interface (abbr. MPI) add a layer of complexity to the written program code that is entirely focused on facilitating distributed execution.
Ultimately, the combination of both levels of parallelization may lead to additional problems, hence distracting programmers from the implementation of the actual algorithm.

While the implementation of distributed algorithms implicates various problems on its own, running these programs in a cost efficient manner represents another elaborate task. Clusters dedicated to running computations in a shared environment should have as little underutilization as possible in order to minimize costs. Therefore the dynamic adaption of resources to the actual performance requirements is a challenge with significant monetary benefits. As a result, cloud services, such as Amazon Elastic Compute Cloud (abbr. EC2), have seen a steady increase in revenue due to their flexible billing options that allow booking resources for short amounts of time\cite{gartner_2017}. Still, a pure cloud approach may introduce several disadvantages, e.g.~higher costs or reduced performance due to geographical distances between the user and the utilized resources. Accordingly, a hybrid approach appears beneficial, providing a steady baseline of performance with local hardware. In the case of computational peaks, additional resources might be booked from an external provider, which allows for lower costs and better quality of service during times with high resource demands.

\section*{Research Goals}
\label{goals}
While a multitude of solutions exists for solving the previously mentioned challenges, many of them only cover partial problems. This thesis aims at providing a framework to programmers that solves all the given problems by meaningfully reusing existing software. Therefore the general goal is to combine present partial solutions and to add individual functionality where necessary. Thus, the following research goals are defined in order to streamline the development:

\begin{description}[style=nextline]
    \item [Heterogeneity]
    The framework should support modern CPUs and GPUs. Thus, devices by the following vendors should be included: Advanced Micro Devices (abbr. AMD), ARM, Intel and NVIDIA. Therefore various workloads and their specific hardware demands can be supported. Additionally, heterogeneous hardware allows for a more granular employment of the required resources. For example, a more cost efficient ARM CPU could be utilized in low demand situations instead of a more potent but also energy demanding Intel CPU.

    \item [Resource Scalability]
    For fixed workloads, the required computational power may be estimated accordingly to determine the appropriate resources. As soon as an infrastructure is provided to multiple users that can submit computations, it becomes challenging to reach a stable utilization of the cluster. Thus, providing static resources to a fluctuating amount of incoming computations likely leads to periods of underutilization or congestions. Therefore it is desirable to have the ability to dynamically adapt the computational power of the cluster. One way to achieve this is the utilization of external cloud services like Microsoft Azure or Amazon EC2, thus forming a hybrid cluster.

    \item [Scalable Speed]
    While the general size of a cluster should be adjustable for overall resource utilization, the allocation of resources to a specific task also has to be considered. It is desirable that users are able to scale the execution speed of their respective workloads as real-world deadlines could put boundaries on the amount of available time for a computation to finish. Therefore it must be possible to dynamically adjust resources for a workload without interrupting the overall execution. With this ability, the framework would be enabled to handle burst scenarios as well as save resources in the case of continuous low computational demand by the current workload.

    \item [Ease of Programming]
    The introduced framework should provide programmers with an easy to use distribution mechanism without adding noticeable overhead to their development process. Preferably the resulting code should be created in a high-level language on a high abstraction level.

    \item [Workload Diversity]
    While the submitted workloads could differ in size and resource requirements, they might also have different hardware demands. For instance, several workloads within the system could be optimized for CPUs and others for GPUs. The framework should support the execution of these workload types and additionally optimize the distribution across available hardware from a global system view.

    \item [Optimized Scheduling]
    Aside from various hardware that workloads can be optimized for, running programs on a hybrid cluster adds the issue of networking distances between the local cluster and the external cloud. Thus, certain tasks may see performance improvements when run locally instead of being initially sent to external resources. It is desirable to take these factors into account and consider network distances and bottlenecks during scheduling decisions.

\end{description}


\section*{Thesis Structure}
\label{structure}

The following chapters are organized as follows. In chapter \ref{background} relevant parallelization and distribution technologies, which are discussed throughout this thesis, are introduced. Chapter \ref{related} showcases various existing research efforts for parallel computations on single machines as well as clusters. In chapter \ref{benchmarking_methodology} the general measurement process for this research is explained, including the hardware setup and chosen workloads. Chapter \ref{main} covers the main contribution of this thesis, a new framework called Dynamic OpenCL. Following explanations for the implemented solutions, chapter \ref{evaluation} includes various performance tests for the framework in different cluster environments. In chapter \ref{demonstration} a reference implementation based on Dynamic OpenCL is showcased that allows users to start cluster computations through a webserver. Ultimately this thesis concludes with chapter \ref{conclusion}, which summarizes the achieved research goals and illustrates future work that aims to overcome current limitations of Dynamic OpenCL.
